随着数据体积的爆发性增长，人们从数据获取的信息也随之增多。然而从海量数据中提取信息去预测未来，却是件很疯狂的工作。信息收集、存储、管理和分析不再受技术的制约，大数据，极富挑战地吸引着越来越多的科学家、分析师，甚至是一般企业管理者或者创新企业和个人。

科学家用自制软件预测未来

日前，Laura Hazard Owen在Gigaom上撰文《How two scientists are using the New York Times archives to predict the future 》，文章很有意思。

这两名分别是来自微软的Eric Horvitz与以色列研究所的Kira Radinsky，他们通过自制软件来分析“纽约时报22年的报纸、维基百科和其它90家网站资源”以预测未来，其中包括：疾病暴发、社会暴乱及死亡，并希望能对阻止上述事件产生帮助。这项研究是挖掘互联网数据并进行各种事件预测的最新举措。

 

其相关研究论文―― 《挖掘网络到预测未来》（PDF）已经发表。为了便于理解，他们举了个例子，如何用分析暴风雨、干旱等自然灾害去预测安哥拉霍乱暴发的方法。通过分析，他们认为可以提前一年预测到霍乱暴发的蔓延。显然，这项在数据挖掘上的最新应用，也足以应对分析新闻、博客和社交媒体来帮助各行各业把握人们的动机的挑战。

从某种意义上来看，之前流行病学专家已经看到了其中一些必然的联系，但是Horvitz和Radinsky认为应该把目标放在“采用启发式评估、经常做回顾性分析”这类研究上，而不是把目标放在做近期指导的预测形成上。他们把软件对比人类的优势归纳于以下4个点：

1. 学习中的优势

软件有能力从大量数据中吸取知识
可以同时监视多个信息源
可以随着时间认知新的概率关联
可以持续的进行实时监控
对可不断增大的未来事件进行预报和警报
2. 不知疲倦的研究

软件在挖掘历史事件和正在发生的事件有天生的优势，可以挖掘出人们可能永远都不会发现的真相 ―― 精力以及惰性决定了人类只注意容易认知或者已被发现的知识。

3. 无偏见的去分析数据及推测结果

软件会忠诚和自动的执行分析，即使发生以下两种情况：

数据分析出的推论与专家预期相反
基于大量的观察以及源数据推测出的结论远低于专家期望
4. 基于更广泛的数据对数据进行分析

系统会对新闻做快速的全方位监测然后做出预测，无论这个新闻出现在报纸上的哪个位置。这种全方位不会被新闻源或者地方性所限制，而是从系统的角度上，比如：一个地方报纸的非主要标题处刊登的葬礼发布，在大的局面上也许是大规模暴动的主要线索。

除此以外，还有非常重要的一点是“ 什么该概括、什么该忽略 ”。

在软件模式的开发过程中，工程师需要面对的一个问题是：许多贫困的非洲国家对一些灾难性事件不做广泛的报道。为了应对这个问题，他们训练软件从以下几点进行概括：“取代只分析卢旺达霍乱暴发――只有很少量案例的历史事件，我们从更广泛的面去考虑这个问题――整个非洲国家的霍乱暴发。”

Horvitz和Radinsky同样教会了软件该忽略什么：比如说1989年3月纽约发生的旱灾，系统会忽略其造成霍乱暴发的可能，因为霍乱依赖与密集的人口基数（比如安哥拉和孟加拉的难民营）和易被污染的水源。

被催化的“机器学习”和各类追踪分析 

Horvitz和Radinsky基于大数据的分析只是代表了应用的一个方面。除此以外，还有很多。

比如，在大数据技术的推动下，飞速发展的机器学习表现的很是突出。IBM之前更有一篇报告提出，5年类计算机获得人类五感将成为现实。确实从技术发展来看，计算机数据处理能力日益增长，涉及领域极其广泛；在未来如同人类一样拥有五感已非不可能。

当然，在数据时代得益的不只是机器学习，还有更多来自行业价值增值：通信行业、智慧医疗、商业运营、城市交通、客户工作分析、广告投放分析、政府事业等等。

在此之前，CSDN云计算频道曾经报道过，研究者们如何使用Twitter和Google去追踪流感的暴发。 
那是去年12月，波士顿和纽约出现流感疫情之后，为了让疫情得到有效的控制，美国卫生官员及应用开发人员是这么应用大数据的：

主要负责防止流感疫情扩散的美国疾病预防控制中心（CDC）已逐渐使用大数据来了解疫情，他们认识到：虽然医生是控制疫情的“主站武器”，但是目前没有足够的疫苗可以普及所有的人群；此外在研制流感疫苗之前，必须要确认不同的流感病毒株，这样生产出来的疫苗才能真正的防止流感的扩散。

而为了确认某个地区的流感菌株，他们同科尔全球性威胁基金进行达成合作；推出了FluNearYou应用程序（13周岁以上市民可以注册），用以监测流感的蔓延程度。从美洲一次的调查报告来做好流感疫情扩散的准备并进行预测。

同时还有一个用以收集社交媒体信息的Germ Tracker（信息收集网站，可以通过地图追踪流感病情的扩散）和挖掘搜索信息的Flu Trends（一款来自Google的流感追踪器，类FluNearYou的监测工具）。 更多信息查看：美国人是如何利用大数据的应用来防止流感的蔓延

大数据分析固然带来了好的一方，比如上面说的训练机器学习、预防流感的蔓延等大家喜闻乐见的大数据应用，但硬币的另一面是，也会让很多人非常不舒服：比如之前纽约市枪支许可证所有者的地址都在Google地图中被标注，严重侵犯了隐私。

事实上，对于大数据应用的讨论仍有很多，美国社会中最激烈的观点就是：开放数据被誉为一个开放的工具服务于民众，但同时却也被激烈的党争所利用，危害公众安全。

重金招揽大数据创新企业

无论如何，充满矛盾的讨论无法阻挡大数据分析的脚步。数据还在呈指数上升，PB存储的成本即使是个人都能承受，大数据挖掘与分析的新工具与技术频频出现。这些创新企业或技术或在针对 大数据的提取，转换，加载，或针对后续的管理，分析，或对最终可视化效果做优化，异彩纷呈。

为此，IT巨头们纷纷主动抛出橄榄枝，重金招揽。尤其是IBM，在收购多家数据分析公司，比如：Netezza、Butterfly以及Tealeaf之后，近期又动作频频。比如日前风传的IBM将收购大数据公司Splunk（虽然是传言，但未必就是空穴来风）；又如IBM宣布的对大数据分析公司Star Analytics的收购计划。

国内创意很多，案例不多

显然，从目前的资料上来看，美国或在资金以及技术规模上占有相当的优势，然而数据的挖掘和分析绝却并非谁所特有的专利。国内，淘宝、百度、腾讯的数据挖掘和分析虽然还没有进行大范围宣传，但每一次应用变化后都有大数据支持。还有近期的12306，无论是并发还是应用，都堪称大数据经典，而后续环节优化（实名制退票、线路优化等），都可以直接归类到大数据分析领域。

有意思的是，数据分析显然不只是大公司才能做的事情，比如上述两位科学家完全通过自制软件就能实现分析，还比如日前一个广为流传的国内数据分析的段子：

 @时代报发表了一篇关于“大数据时代的挣钱模式”的微博（未经考究其真实性）：

一小伙专门应聘上海均价 4万高档小区的物业管理，自己配了扫描枪，每天就盯着小区垃圾堆，看见有条形码就扫描，晚上回家把数据整理出来，得出这小区喝什么水吃什么油买什么衣服，整个小区的消费品类偏好和品牌偏好一清二楚，再形成报告卖给大公司，报告价值数十万。
不论是否真实，其基本上0资本玩转数据的思考还是值得重视的。有网友们就认为：

@招福象：如果公民的数据就这样进行收集，那么个人的隐私、甚至人身安全如何保障？早期的市场调查机构就有去翻翻小区的垃圾，通过那些某品牌饮料瓶的出现的频率，来推断出饮料的市场占有率跟消费饮食习惯，甚至竞争对手的情况。
再回到国内主流观点，日前 @北大新媒体发布关于数据预测未来的微博后，大家对机器学习与大数据的看法：

@张栋_机器学习（原百度科学家，凤巢系统架构师；原Google 研究员，机器学习博士）在其微博上发表的关于大数据的看法：

1. 中国互联网做大的公司都是大数据公司：大数据是互联网技术和商业模式发展的驱动力 
2. 这些公司有一个共同点：在初期，商业模式上都经历了一个摸索的过程  
3. 做大数据研发最好能在大公司内部：大公司经过长时间积累，才有大数据，大数据的作用是对已有的成熟商业模式的效率提升，或者是找到新的商业模式：在大公司内部做大数据，可以更快的看到效果 
4. 如果要做大数据的创业公司：要有长远的心态，做大数据公司一定是慢公司：数据积累需要时间，商业模式摸索也需要时间
对大数据与数据挖掘持乐观态度的有：

@刘-Allen： 随着大数据的发展，数据挖掘和商业智能会得到越来越多的重视。 
@司学峰： 经常收到预测分析建模国际会议与营销相关英文邮件，国内火起来有待时日。 
@zju正青春人： 技术的进步让实证研究更进一步。
当然还有抱谨慎态度的：

@统计之都:（大数据+数据挖掘技术==知识），这个语句到底是返回FALSE还是TRUE，现在还没有定论呢，我们还是谨慎乐观吧！
更有热心的朋友考虑到了负载问题：

@智能矩阵： 分析下60年来的人民日报，会不会宕机呢？